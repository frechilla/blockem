(Note: Before you read this document you might think of having a look at 
 http://blockem.sourceforge.net/devel.html for a more readable, and probably
 more updated, version of it)

WRITING ARTIFICIAL INTELLIGENCE FOR 1vs1 GAMES 

  To understand the Artifical intelligence (AI) used in Blockem, a few terms must
be understood first:
* Game tree (from wikipedia) is a directed graph whose nodes are positions in a 
  game and whose edges are moves. The complete game tree for a game is the game 
  tree starting at the initial position and containing all possible moves from 
  each position.
* Minimax (from wikipedia) is a decision rule used in game theory (...) for 
  minimising the possible loss while maximising the potential gain
* Alpha-beta prunning (from wikipedia) It is a search with adversary algorithm
  used commonly for machine playing of two-player games (Tic-tac-toe, Chess, 
  Go, etc.). It seeks to reduce the number of nodes that are evaluated in the 
  search tree by the minimax algorithm

  As you could have guessed, Blockem AI is based on the MiniMAx algorithm with 
alpha-beta prunning, to reduce the number of nodes in the search tree ensuring 
the same result as it would be got with Minimax.
The big deal about the Minimax-alphabeta algorithm is the evaluation function, 
which gives a numeric value to a specific configuration of the game. In blockem
the configuration of the game is defined by the board, the moving player and the
opponent, so the C++ interface of the evaluation function was decided to be:

int32_t EvalFunction(
             const Board  &a_board,
             const Player &a_playerMe,
             const Player &a_playerOpponent);

  Inside a class called Heuristic (in heuristic.h) there's a typedef which 
defines exactly this interface:

class Heuristic {

    /* ... */ 
    
    typedef int32_t (*EvalFunction_t) 
            (const Board &, const Player &, const Player &); 
    
    /* ... */ 
}; 

  You can easily write a new heuristic and make it available in the blockem GUI. 
The following explanation applies to blockem version 0.2.0 or higher, where
the process of adding new heuristics has been improved and simplified.


 1) Implement a function that suits the 'EvalFunction' Interface. A very 
    obvious one (though too simple) might be based on the number of squares
    each player managed to allocate on the board.
 
    int32_t SimpleEvalFunction(
            const Board  &a_board,
            const Player &a_playerMe,
            const Player &a_playerOpponent)
    {
        int32_t squaresMe = 0;
        int32_t squaresOpponent = 0;
        int32_t rv = 0;
   
        for (uint8_t rowCount = 0; 
                     rowCount < a_board.GetNRows() ; 
                     rowCount++)
        {
            for (uint8_t columnCount = 0; 
                        columnCount <  a_board.GetNColumns(); 
                        columnCount++)
            {
                if (a_board.IsPlayerInCoord(rowCount, columnCount, a_playerMe))
                {
                    squaresMe++;
                }
                else if (a_board.IsPlayerInCoord(rowCount, columnCount, a_playerOpponent))
                {
                    squaresOpponent++;
                }
            }
        }
   
        rv += squaresMe;
        rv -= squaresOpponent;
   
        return rv;
    }
    
    If we take the former heuristic as the base one, we can slightly improve 
    its performance taking into account also the nucleation points. The 
    following code is the heuristic called "Simple" in the configuration
    dialog. It assigns twice as much of importance to create a new nucleation
    point than removing one from the opponent. You could easily adapt this
    heuristic to something that is only focused on stopping the opponent, 
    or vice-versa. Note that there are a few functions defined in rules.h that 
    might help you out to write a powerful evaluation function (things like 
    IsThisANucleationPoint, and so on...) 

    int32_t SimpleEvalFunction(
            const Board  &a_board,
            const Player &a_playerMe,
            const Player &a_playerOpponent)
    {
        int32_t squaresMe = 0;
        int32_t squaresOpponent = 0;
        int32_t rv = 0;
   
        for (uint8_t rowCount = 0; 
                     rowCount < a_board.GetNRows() ; 
                     rowCount++)
        {
            for (uint8_t columnCount = 0; 
                         columnCount <  a_board.GetNColumns(); 
                         columnCount++)
            {
                if (a_board.IsPlayerInCoord(rowCount, columnCount, a_playerMe))
                {
                    squaresMe++;
                }
                else if (a_board.IsPlayerInCoord(rowCount, columnCount, a_playerOpponent))
                {
                    squaresOpponent++;
                }
            }
        }
   
        rv += squaresMe*4;
        rv += a_playerMe.NumberOfNucleationPoints()*2;
        rv -= squaresOpponent*4;
        rv -= a_playerOpponent.NumberOfNucleationPoints();
   
        return rv;
    }

 2) All the available heuristics are added to an array defined in the Heuristic
    class called m_heuristicData. This array is defined in heuristic.h as:
    
    
    /// pointer to the heuristic calculator function 
    typedef int32_t (*EvalFunction_t)(const Board &, const Player &, const Player &); 
    
    /// types of heuristic. If you add a heuristic here you MUST add a proper description 
    /// to Game1v1Config in the constructor using a Game1v1Config::sHeuristicConfig_t 
    typedef enum { 
        e_heuristicStartCount = 0, // this element must be always 0 and must be at the start 
        
        e_heuristicInfluenceArea = e_heuristicStartCount, 
        e_heuristicInfluenceAreaEastwood, 
        e_heuristicNKWeightedv1, 
        e_heuristicCentreFocused, 
        e_heuristicSimple, 
        e_heuristicRandom, 
        
        e_heuristicCount, // stores the amount of heuristics. Must be always at the end 
    } eHeuristicType_t; 
    
    /// heuristic data to be used in the heuristics config array 
    typedef struct 
    { 
        eHeuristicType_t m_type; 
        EvalFunction_t m_evalFunction; 
        const char* m_name; 
        const char* m_description; 
    } sHeuristicData_t; 
    
    static const sHeuristicData_t m_heuristicData[e_heuristicCount]; 
    
    
    At the top of heuristic.cpp the list of available heuristic is instantiated.
    Note that all strings are defined inside a call to N_(). This call tells 
    the translation engine (gettext) to mark the string as translatable. 
    This must be done in your brand new heuristic to ensure its description is
    translated by the i18n team. 
    
    // instantiate the const heuristic data array. Heuristics must be defined here
    // in the same order they are described in Heuristic::eHeuristicType_t in heuristic.h
    const Heuristic::sHeuristicData_t Heuristic::m_heuristicData[e_heuristicCount] =
    {
        {e_heuristicInfluenceArea,
         Heuristic::CalculateInfluenceAreaWeighted,
         N_("Influence Area"),
         N_("Uses the influence areas that a user's pieces create on the board to determine the quality of a move")
        },
        {e_heuristicInfluenceAreaEastwood,
         Heuristic::CalculateInfluenceAreaWeightedEastwood,
         N_("Mr. Eastwood"),
         N_("Modified version of \"Influence Area\". When in doubt it will try to block you out")
        },
        {e_heuristicNKWeightedv1,
         Heuristic::CalculateNKWeightedv1,
         N_("NK weighted"),
         N_("The more Nucleation points the better. NK points are more important in the middle of the board at the beginning")
        },
        {e_heuristicCentreFocused,
         Heuristic::CalculateCentreFocused,
         N_("Centre focused"),
         N_("It has a tendency to create nucleation points over the centre of the board")
        },
        {e_heuristicSimple,
         Heuristic::CalculateSimple,
         N_("Simple"),
         N_("Takes into account only the amount of squares of the deployed pieces")
        },
        {e_heuristicRandom,
         Heuristic::CalculateRandom,
         N_("Random"),
         N_("Random heuristic. Evaluation function returns a random value so any heuristic can be checked against it")
        },
    };
    
    To add a brand new Heuristic in a function called, for example, 
    "MyCustomisedHeuristic", first of all you must add an entry in the 
    eHeuristicType_t enum in heuristic.h

    /* ... */ 
    typedef enum 
    { 
        e_heuristicStartCount = 0, // this element must be always 0 and must be at the start 
        
        e_heuristicInfluenceArea = e_heuristicStartCount, 
        
        /* ... */ 
        
        e_heuristicRandom, 
        e_heuristicMyCustomisedHeuristic, // <-- Your brand new heuristic 
        
        e_heuristicCount, // stores the amount of heuristics. Must be always at the end 
    } eHeuristicType_t; /* ... */ 

    And then add it to the m_heuristicData array at the top of heuristic.cpp. 
    Don't forget to write the all strings inside the call to the N_() function. 
    
    const Heuristic::sHeuristicData_t Heuristic::m_heuristicData[e_heuristicCount] = 
    { 
        /* ... */ 
        
        {e_heuristicRandom, 
         Heuristic::CalculateRandom, 
         N_("Random"), 
         N_("Random heuristic. Evaluation function returns a random value so any heuristic can be checked against it") }, 
        {e_heuristicMyCustomisedHeuristic, // as defined in eHeuristicType_t in heuristic.h 
         Heuristic::MyCustomisedHeuristic, // pointer to the heuristic function you wrote 
         N_("MyCustomised"), // Name of the heuristic. It'll be used in the GUI 
         N_("This is my brand new...") // Description of your heuristic. It'll also be used in the GUI 
        } 
    }; 
    
 3) Save all the changes, recompile blockem and your heuristic will be 
 magically available to be selected in the "new Game" and the "configuration" 
 menu. You will be able to test your new heuristic against the "random" one, or
 try to beat it playing blockem in a 1vs1 game. 


DEPTH OF THE SEARCH TREE

  The depth of the search tree defines how many pieces are "virtually" put down 
by the minmax algorithm to test how good a specific move is. Depth 3 means 
minimax will put down a piece of the player whose move is being calculated, 
then it will put down a piece of the opponent (normally the human user) and 
finally another piece of the player whose move is being calculated. Once this 
is done the evaluation function is applied to that specific configuration of
the board and the value returned is used to "tag" it. The set of 3 moves which
maximises the minimax algorithm at the end of the whole process is picked as 
winner, and the move returned by the MinMax algorithm will be the corresponding
first move of the "winner" set.

  Minimum depth possible is 1, where no futurising is done. Evaluation function 
is calculated after the user whose move is being calculated "virtually" puts 
down each available piece in every possible place. An example for a bigger
depth, for example 5, means 3 pieces of the "computer" player and 2 of the 
"human" one will be place on the board before the evaluation method is run.
   
  Depth can also be set to an even number, though it is discouraged because 
better results have been observed using an odd number. This is due to the fact 
that an odd number maximises the current user while an even number tries to 
minimise the opponent.
   
  Obviously, the deeper you calculate the search tree, the better. But if the
search tree is too big, for instance because there are too many pieces left,
computing a new depth for the search tree is very expensive in time, which can 
be bad for the user experience.

  Let's use an example to explain it: At the beginning of the game each player 
has 21 pieces left. Since placing this 1st piece on the board has different 
rules than the rest of the pieces, let's assume both players put down the 
simplest of the pieces, the baby piece (1 square). It has 4 nucleation 
points (corners).
   
  If we set MinMax to calculate with depth = 1 it will call the evaluation 
function once per allowed movement in each nucleation point, that might be, 
roughly, 90 different configurations (20 pieces + rotated pieces + mirror 
pieces + rotated and mirrored pieces...) multiplied by 4 nucleation points 
equals 360 times. In reality this number is even bigger, because some pieces 
can be put down more than once with the same configuration in the same 
nucleation point (for instance, think of how many different ways you can place
a the cross piece, which can't be rotated or mirrored, next to a baby piece)
   
  Let's assume there will be always around 360 different possibilities (as I said
it is even worse, there are several ways to deploy a piece in a nucleation 
point, and normally there are more than only 4 corners). Anyway, assuming this
beautiful world of "only 360", the next depth in the search tree will be 
360 * 360 = 129,600 (360 new configuration per each old possibility), and the 
following one (depth 3), will be 360*360*360 = 46,656,000!!!

  Luckily enough things are not that bad. The alpha beta prunning takes care of 
lots of different useless branches of the search tree before they are 
calculated, but this example shows why you must use the depth parameter with 
a lot of care.
   
   
IMPROVING PERFORMANCE OF THE HEURISTICS
   
  As it is described in the wikipedia about the alpha-beta prunning, "Further 
improvement can be achieved without sacrificing accuracy, by using ordering 
heuristics to search parts of the tree that are likely to force alpha-beta 
cutoffs early, For example, in chess, moves that take pieces may be examined 
before moves that do not".
   
  To improve speed in the Blockem implementation of the alpha-beta prunning, 
bigger pieces are always checked before smaller ones (they are more likely to 
be better as an important part of the evaluation function must be the amount 
of squaresd eployed on the board). They are checked in inverse order as they 
are defined in ePieceType_t enum in Piece.h, so pieces in that enum are sorted
from worse to better (from less likely to do a good move to more likely):
   
    typedef enum
    {
        // if this enum is modified, ensure all the constants are updated 
        // accordingly
        e_minimumPieceIndex = 0,
       
        e_1Piece_BabyPiece   = e_minimumPieceIndex,
        e_2Piece_TwoPiece    = 1,
        e_3Piece_LongPiece   = 2,
        
        /* ... */
        
        e_5Piece_SafPiece = 18, 
        e_5Piece_WPiece = 19, 
        e_5Piece_Cross = 20, 
        
        e_numberOfPieces = 21, 
        e_noPiece = 22, 
        
    } ePieceType_t;

   
  Another design step was made to trim out possibly useless branches of the 
search tree. It sacrifices a bit of accuracy assuming no 4,3,2 or 1 square 
pieces are put down before the 6th move. Assume makes an ass out of u and me, 
but sometimes assumptions must be made. A constant has been defined in 
game1v1.cpp (MIN_5SQUARE_PIECES_AT_START) which describes how many 5-square 
pieces will be put in-a-row before even considering to put a 4,3,2 or 1 square 
piece on the board.

  Computing speed has been also improved using tools as gprof to understand 
where the biggest amount of computing was being spent. It doesn't mean it's 
perfect though. Pieces are at the moment described as arrays of coordinates, 
while describing them as pure bits in a uint32_t o(or uint64_t) would improve 
calculation speed (at least that is what I think). Also the calculation 
algorithm is not multithreaded, though building up a search tree looks like a 
good (and relatively easy) thing to be multithreaded.
 
  And that pretty much describes what I've done so far regarding the heuristics
in blockem. If you think this may be of your interest, code away and have fun! 
(and if you improve it, please share it with me!)

